
# 语音识别基础复习提纲（入门友好版）

> 建议先整体浏览一遍，再按小节慢慢看。  
> 你可以把这份当成“语音识别最小知识清单”。

---

## 0. 学什么？大概在干嘛？

语音识别的目标：  
**把“声音信号” → 变成“文本（字 / 单词）”。**

大体流程：

1. 录到的声音：一长串波形信号  
2. 特征提取：从波形里“抠”出有用的数字特征（MFCC 等）  
3. 建模与识别：
   - 早期：DTW、GMM、HMM 等传统方法
   - 现在：神经网络（RNN、CTC 等），很多是端到端

---

## 一、语音基本概念

### 1. 音节（syllable）

- **定义**：听起来像“一个拍子”的语音单位。
- 汉语：一般 **一个字 = 一个音节**  
  - 例：**“红”** = 一个音节
- 英语：一个单词可以有多个音节  
  - 例：**“computer”** 有 3 个音节：com / pu / ter

**汉语音节组成（三件套）：**

1. 声母（开头的辅音）—— 如 “hóng” 里的 **h**
2. 韵母（后面的元音+鼻音等）—— “hóng” 里的 **ong**
3. 声调（第几声）—— “hóng” 是 **第二声**

---

### 2. 音素（phone）

- **定义**：从音节中拆出的最小语音单位，不能再分。
- 例：**“红”** 的读音 **/hong/** 可以拆成 3 个音素：
  - **h**、**o**、**ng**
- 你可以把 **音素** 理解成“发音的小块积木”。

---

### 3. 音位（phoneme）

- **定义**：**能区分词义** 的音素类别。
- 例：
  - **b** 和 **p**：
    - “bian” vs “pian”
    - “bu” vs “pu”
  - 因为 b 和 p 会让词的意思变了 → 所以它们是不同的 **音位**。

> 直观记忆：
> - **音素**：实际发出的“声音片段”
> - **音位**：在语言里“有区别作用”的那一类音素  
>   （更偏“抽象类别”一些）

---

## 二、特征提取（MFCC 是核心）

机器不能直接理解“生的波形”，  
所以先要把一段语音 → 变成一串数字特征。

### （一）基本流程（非常重要）

1. **分帧（frame）**
   - 把连续的语音信号按时间切成一段一段
   - 每帧长度：一般 **20–50 ms**
   - 理由：这么短的时间内，声音可以近似看作“稳定”的

2. **做傅里叶变换 → 得到频谱**
   - 把“时间信号” → 变成“频率信号”
   - 频谱可以理解为：  
     **每个频率上有多大能量**
   - 频谱里：
     - **包络（envelope）**：整体形状 → 和音色、语音内容更相关  
     - **精细结构**：细细的波动 → 和音高（pitch）更相关

3. **用三角滤波器 → 得到 Mel 频谱**
   - 用很多个重叠的“**三角形滤波器**”在频率轴上做加权。
   - 这些滤波器的中心频率不是均匀的，而是按 **Mel 频率尺度** 分布
   - 目的：**模拟人耳对频率的感知：**
     - 低频：人耳更敏感
     - 高频：分辨能力差一些 → 用更稀疏的滤波器

4. **从 Mel 频谱 → 提取 MFCC 特征**
   - 对 Mel 频谱做一系列数学处理（log + DCT 等）
   - 得到一串系数：**MFCC（Mel 频率倒谱系数）**

---

### （二）MFCC（Mel-Frequency Cepstral Coefficients）

可以简单记：  
**“描述语音音色的低维特征”**。

#### 1. 公式大意

你不需要死记公式，只要知道大致过程：

1. 对每一帧语音做 FFT → 得到频谱 |X(f)|
2. 取对数：log |X(f)|
3. 做 DCT（离散余弦变换），把频域信息变到“倒谱域”

可以简写成（概念上）：

> **倒谱 = IFFT( log |频谱| )**

得到的系数就是 **倒谱系数**，选前面几维就是 **MFCC**。

#### 2. MFCC 的优点

- **去掉基频信息**，更关注“音色”，对说话内容更有用
- 符合人耳对声音的感知习惯（Mel 频率尺度）
- **维度低**（通常十几维），便于后续建模

#### 3. MFCC 的缺点

- 每次只看一个短帧 → **“视野”比较小**
- 容易受到：
  - 噪声
  - 回声
  - 录音设备滤波 的影响

---

## 三、孤立词识别（只识别单个词）

**“孤立词”**：一次只说一个词，中间有明显停顿。  
例如：说一声“开启”，系统只需要识别这一个词。

### （一）模板比较法

两种常见方式：

1. **单模板：DTW（动态时间规整 / 扭曲）**
   - 每个词只有一个模板
   - 用 DTW 对齐待识别语音和模板，算相似度

2. **多模板：GMM（高斯混合模型）**
   - 每个词用一个 GMM（或者多个状态，每个状态一个 GMM）
   - 用**概率密度**来衡量相似度，而不是简单的欧氏距离

---

### （二）DTW（Dynamic Time Warping）

**解决的问题：**

- 两段语音：
  - 内容相同
  - 但说话速度不同、长短不同
- 普通按时间对齐会对不上 → 需要“时间扭曲”

**核心思想：**

- 把两条时间序列（特征向量序列）按顺序对齐
- 允许“拉伸”或“压缩”时间轴
- 使用动态规划算法，找到总距离（一般是欧氏距离之和）最小的对齐路径
- 最小总距离 = 两段语音的“不相似程度”

---

### （三）GMM（Gaussian Mixture Model）

**1. 是什么？**

- **多个高斯分布的加权和**：
  - 一个高斯拟合不了复杂数据
  - 很多高斯叠加起来，就可以拟合非常复杂的分布

**2. 单个高斯分布公式（记个形状就好）**：

\[
f(x)=\frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x-\mu)^2}{2 \sigma^2}}
\]

- μ：均值
- σ²：方差

GMM 就是很多这样的高斯分布相加。

**3. 训练方法：EM（期望最大化）算法**

- 交替两步：
  - E 步：根据当前参数，估计每个样本属于哪个高斯的概率
  - M 步：根据这些概率，重新更新每个高斯的参数（均值、方差、权重）

**4. 用在孤立词识别的流程（简化版）：**

1. 对语音做 **DTW**（必要时）对齐到统一时间尺度
2. 把每个词建模成若干状态，每个状态用一个 GMM
3. 输入一段新语音 → 提取 MFCC
4. 计算这段 MFCC 在每个词模型上的概率
5. **哪个词模型概率最高 → 识别为哪个词**

---

## 四、连续语音识别：HMM 与大词汇量识别

### （一）HMM（隐马尔可夫模型）

用来描述：**“隐藏的状态序列”产生“可观察到的特征序列”**。

在语音识别里：

- **隐藏状态**：音素的状态（如某个音素的开始 / 中间 / 结束状态）
- **观测值**：每一帧的特征（MFCC）

**1. HMM 的三个核心部分：**

1. **状态转移矩阵 A = (aᵢⱼ)**
   - 表示从状态 j 跳到状态 i 的概率：
   - \( a_{ij} = P(x_t = i \mid x_{t-1} = j) \)

2. **观测概率矩阵 B = (bⱼ(k))**
   - 表示在状态 j 下，产生观测值 yₖ 的概率：
   - \( b_j(k) = P(y_k \mid x_j) \)
   - 在语音里，常用 GMM 或神经网络来表示这个概率

3. **初始状态分布 π**
   - 一开始在各个状态的概率 \( \pi_i = P(x_1 = i) \)

**2. 用 HMM 做识别（简化理解）：**

目标：给定特征序列 X，找到最可能的词序列 W。

\[
W^* = \arg \max_W P(W \mid X)
    = \arg \max_W \frac{P(X \mid W) P(W)}{P(X)}
\]

- \(P(X \mid W)\)：声学模型（HMM）给出的“发出这些特征的概率”
- \(P(W)\)：语言模型给出的“这句话在语言上是否合理的概率”
- \(P(X)\)：对所有 W 都一样，可忽略

---

### （二）大词汇量语音识别（LVCSR）

当词汇量**非常大**（几千、几万词）时：

- 如果给 **每个词单独建一个 HMM**，会非常麻烦
- 解决方法：**按“音素”建模，而不是按“词”**

**1. 核心策略**

- 不为单个单词训练 HMM
- 改为：**为每个音素训练一个 HMM**

**2. 组合方式**

1. **音素 HMM → 单词 HMM**
   - 用词典告诉你：
     - 这个词由哪些音素构成
   - 把对应音素的 HMM 串联起来，就得到这个词的 HMM

2. **单词 HMM + 语言模型 → 句子 HMM（或更大的网络）**
   - 语言模型告诉你：
     - 某个词后面接另一个词的概率有多大
   - 和 HMM 结合后，就可以在**词序列**上做解码

---

## 五、语音识别系统评价与深度学习方法

### （一）基于 GMM-HMM 的传统系统

1. **结构**：  
   - 前端特征：MFCC  
   - 声学模型：GMM-HMM  
   - 语言模型：n-gram 等

2. **核心评价指标：WER（词错误率）**

\[
\text{WER} = \frac{\text{插入错误数} + \text{删除错误数} + \text{替换错误数}}
{\text{参考答案（标准文本）的词数}}
\]

- 插入：系统多识别了一个本来没有的词
- 删除：系统漏掉了一个应该识别出的词
- 替换：把一个词认错成了另一个词

---

### （二）基于神经网络的语音识别

#### 1. 常见结构

- **Tandem 结构**
  - 神经网络先做特征提取
  - 提取出的“高级特征”再送进 GMM-HMM

- **Hybrid 结构**
  - 神经网络直接代替 GMM，给出 HMM 每个状态的发射概率

#### 2. RNN 在语音识别中的应用

- RNN（循环神经网络）适合处理**序列数据**（如语音帧序列）
- 理想情况：完全替代 HMM
- 实际中：
  - RNN 多用于：
    - 特征提取
    - 或者作为声学模型的一部分
  - HMM 通常仍保留，用来：
    - 训练时提供音素起止时间
    - 解码时提供状态转移概率

#### 3. Grapheme + CTC 的端到端系统

- **Grapheme**：直接用 **字母 / 字符** 做输出单位（不再显式用音素）
- **CTC（Connectionist Temporal Classification）损失**：
  - 只关心：**预测序列 和 真实文字序列 是否匹配**
  - 不需要：
    - 预先对齐每一帧对应哪个音素 / 字符
    - 设置复杂的状态转移概率
- 好处：**训练过程更简单，更像黑盒从“语音 → 字符”**

---

## 复习建议（给完全新手）

1. **先记名词，对上号**
   - 音节 / 音素 / 音位  
   - MFCC / DTW / GMM / HMM / WER / CTC 等
2. **再理一条“大流程线”**
   - 声音 → 分帧 → FFT → Mel 滤波 → MFCC → 模型（GMM-HMM / 神经网络）→ 文字
3. **把几个“成对概念”搞清楚**
   - DTW vs HMM（前者对齐时间，后者做概率建模）
   - GMM vs 神经网络（都可以当声学模型）
   - 传统 GMM-HMM vs CTC 端到端
4. **遇到公式先理解“意思”，不要急着记字母**
   - 公式多是“概率”、“距离”的数学写法，本质逻辑要紧。

你可以先按这份提纲多看几遍，如果你愿意，下一步我可以帮你出一份**配套小练习题（选择题＋问答题）**，专门针对这些知识点。  






# 语音识别复习知识点

## 一、语音基本概念 ⭐

### 1.1 三个基本单位（简答重点）

| 概念     | 定义                  | 举例                       |
| ------ | ------------------- | ------------------------ |
| **音节** | 听觉可自然察觉的最小语音单位      | 汉字"红"是1个音节；English有2个音节  |
| **音素** | 从音节中拆分出的最小语音单位，不可再分 | "红"拆分为 h、o、ng 三个音素       |
| **音位** | 能够区分语义的音素           | b和p是不同音位（"不"bu vs "铺"pu） |

**关系**：音节 > 音素 ≥ 音位

---

## 二、特征提取 ⭐⭐

### 2.1 特征提取流程（简答重点）

```
原始语音信号
    ↓
① 分帧：截取20-50ms的信号帧
    ↓
② 傅里叶变换：计算频谱
    · 包络 → 音色（核心信息）
    · 精细结构 → 音高（用处小）
    ↓
③ 三角滤波：得到Mel频谱（模拟人耳特性）
    ↓
④ 处理：得到MFCC特征
```

### 2.2 MFCC（梅尔倒谱系数）⭐⭐⭐

**核心公式**：
$$\bar{X}(q) = IFFT(\log |X(f)|)$$

**关键操作**：Log + DCT → 信号回到倒谱域

**优点**（简答可能考）：

* ✓ 排除基频干扰
* ✓ 符合人耳听觉习惯
* ✓ 特征维度低

**缺点**：

* ✗ 视野范围小
* ✗ 易受噪声、回声、滤波影响

---

## 三、孤立词识别技术 ⭐⭐

### 3.1 模板比较法

| 模板类型 | 使用算法        |
| ---- | ----------- |
| 单模板  | DTW（动态时间规整） |
| 多模板  | GMM（高斯混合模型） |

### 3.2 DTW算法

**作用**：计算不同长度、不同节奏时间序列的相似度

**原理**：

* 通过动态规划扭曲时间序列
* 按顺序匹配相似帧
* 总距离 = 各帧欧氏距离之和

**适用场景**：语音长度、语速不同时的匹配

### 3.3 GMM（高斯混合模型）⭐⭐

**本质**：多个高斯分布的叠加

**高斯分布公式**（可能考计算）：
$$f(x) = \frac{1}{\sqrt{2\sigma^2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$

**训练方法**：EM算法

**识别步骤**：

1. DTW对齐语音与模型
2. 计算模型各状态的GMM
3. 求MFCC在各状态的概率
4. 选取概率最大的模型

---

## 四、语音识别技术 ⭐⭐⭐

### 4.1 HMM（隐马尔可夫模型）核心要素

**三大组成部分**（简答重点）：

| 组成     | 符号           | 含义                                  |
| ------ | ------------ | ----------------------------------- |
| 状态转移矩阵 | $A=(a_{ij})$ | $Pr(x_{i_t} | x_{j_{t-1}})$ 状态间转移概率 |
| 混淆矩阵   | $B=(b_{ij})$ | $Pr(y_i | x_j)$ 观测概率                |
| 初始状态向量 | $\pi$        | 系统初始化状态概率                           |

**识别公式**（可能考计算）：
$$W^* = \arg\max P(W|X) = \arg\max \frac{P(X|W)P(W)}{P(X)}$$

* $P(X|W)$：声学模型概率
* $P(W)$：语言模型概率

### 4.2 大词汇量语音识别 ⭐⭐

**核心思想**：

* ❌ 不为每个单词训练HMM
* ✅ 为每个音素训练HMM

**HMM复合方式**（简答重点）：

```
音素HMM → (词典拼接) → 单词HMM → (与语言模型复合) → 语言HMM
```

---

## 五、语音识别系统评价 ⭐⭐

### 5.1 词错误率（WER）⭐⭐⭐

**计算公式**（必考计算题）：
$$WER = \frac{插入错误数 + 删除错误数 + 替换错误数}{标准答案长度} \times 100%$$

**举例**：

* 标准答案：我 今天 去 学校（4个词）
* 识别结果：我 昨天 学校（3个词）
* 替换错误：1个（今天→昨天）
* 删除错误：1个（去被删除）
* WER = (1+1+0)/4 = 50%

### 5.2 基于神经网络的系统

**主要结构**：

* Tandem结构
* Hybrid结构

**RNN的应用**：

* 理想：直接替代传统模型
* 实际：多用于特征提取或声学模型
* HMM仍保留作用：

  * 训练时：提供音素起止时间
  * 解码时：提供状态转移概率

**Grapheme系统（端到端）**：

* 采用CTC（连接时序分类）
* 无需预先对齐
* 无需设置转移概率
* 只关注预测序列与真实序列匹配度

---

## 六、重点对比总结

### 6.1 GMM vs HMM

| 对比项    | GMM    | HMM    |
| ------ | ------ | ------ |
| 用途     | 孤立词识别  | 连续语音识别 |
| 建模对象   | 静态特征分布 | 时序状态转移 |
| 是否考虑时序 | 否      | 是      |

### 6.2 传统方法 vs 神经网络方法

| 方法      | 特征提取    | 声学模型 | 解码  |
| ------- | ------- | ---- | --- |
| GMM-HMM | MFCC    | GMM  | HMM |
| 混合系统    | MFCC或NN | NN   | HMM |
| 端到端     | 原始信号    | NN   | CTC |

---

## 七、可能的考试题型

### 简答题准备方向

1. 解释音素、音位、音节的区别
2. MFCC的优缺点
3. HMM的三大要素
4. 大词汇量识别的策略
5. 特征提取的完整流程

### 计算题准备方向

1. **WER计算**（必考⭐⭐⭐）
2. 高斯分布概率计算
3. HMM概率计算（状态转移、观测概率）

---

## 八、学习建议

✅ **必须掌握**：

* WER计算方法
* MFCC的作用和优缺点
* HMM三要素
* 特征提取流程

✅ **理解即可**：

* DTW的动态规划原理
* EM算法细节
* 神经网络结构细节
