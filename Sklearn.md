# Scikit-learn (sklearn) è¯¦è§£

## ä¸€ã€ç®€ä»‹

**Scikit-learn** æ˜¯Pythonä¸­æœ€æµè¡Œçš„æœºå™¨å­¦ä¹ åº“ï¼Œæä¾›äº†ç®€å•é«˜æ•ˆçš„æ•°æ®æŒ–æ˜å’Œæ•°æ®åˆ†æå·¥å…·ã€‚

### ç‰¹ç‚¹

* ğŸ¯ ç®€å•æ˜“ç”¨çš„APIè®¾è®¡
* ğŸ“Š æ¶µç›–å¤§éƒ¨åˆ†ç»å…¸æœºå™¨å­¦ä¹ ç®—æ³•
* ğŸ”§ ä¸NumPyã€Pandasæ— ç¼é›†æˆ
* ğŸ“– æ–‡æ¡£å®Œå–„ï¼Œç¤¾åŒºæ´»è·ƒ
* ğŸ†“ å¼€æºå…è´¹ï¼ˆBSDè®¸å¯è¯ï¼‰

## äºŒã€å®‰è£…

```bash
pip install scikit-learn
# æˆ–
conda install scikit-learn
```

## ä¸‰ã€æ ¸å¿ƒæ¨¡å—

### 1. **ç›‘ç£å­¦ä¹ ç®—æ³•**

```python
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# åˆ†ç±»ç®—æ³•
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

# å›å½’ç®—æ³•
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
```

### 2. **æ— ç›‘ç£å­¦ä¹ ç®—æ³•**

```python
# èšç±»
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering

# é™ç»´
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
```

### 3. **æ•°æ®é¢„å¤„ç†**

```python
from sklearn.preprocessing import (
    StandardScaler,      # æ ‡å‡†åŒ–
    MinMaxScaler,        # å½’ä¸€åŒ–
    LabelEncoder,        # æ ‡ç­¾ç¼–ç 
    OneHotEncoder        # ç‹¬çƒ­ç¼–ç 
)

from sklearn.impute import SimpleImputer  # ç¼ºå¤±å€¼å¤„ç†
```

### 4. **æ¨¡å‹é€‰æ‹©ä¸è¯„ä¼°**

```python
from sklearn.model_selection import (
    train_test_split,    # æ•°æ®é›†åˆ’åˆ†
    cross_val_score,     # äº¤å‰éªŒè¯
    GridSearchCV,        # ç½‘æ ¼æœç´¢
    RandomizedSearchCV   # éšæœºæœç´¢
)

from sklearn.metrics import (
    accuracy_score,      # å‡†ç¡®ç‡
    precision_score,     # ç²¾ç¡®ç‡
    recall_score,        # å¬å›ç‡
    f1_score,           # F1åˆ†æ•°
    confusion_matrix,    # æ··æ·†çŸ©é˜µ
    roc_auc_score       # AUCå€¼
)
```

## å››ã€å…¸å‹å·¥ä½œæµç¨‹

### å®Œæ•´ç¤ºä¾‹ï¼šåˆ†ç±»ä»»åŠ¡

```python
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# 1. åŠ è½½æ•°æ®
iris = load_iris()
X, y = iris.data, iris.target

# 2. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 3. æ•°æ®é¢„å¤„ç†
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. è®­ç»ƒæ¨¡å‹
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)

# 5. é¢„æµ‹
y_pred = model.predict(X_test_scaled)

# 6. è¯„ä¼°
print("æ··æ·†çŸ©é˜µ:\n", confusion_matrix(y_test, y_pred))
print("\nåˆ†ç±»æŠ¥å‘Š:\n", classification_report(y_test, y_pred))
print("å‡†ç¡®ç‡:", model.score(X_test_scaled, y_test))
```

### å›å½’ä»»åŠ¡ç¤ºä¾‹

```python
from sklearn.datasets import make_regression
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# ç”Ÿæˆæ•°æ®
X, y = make_regression(n_samples=100, n_features=1, noise=10)

# åˆ’åˆ†æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# è®­ç»ƒ
model = LinearRegression()
model.fit(X_train, y_train)

# é¢„æµ‹
y_pred = model.predict(X_test)

# è¯„ä¼°
print("MSE:", mean_squared_error(y_test, y_pred))
print("RÂ²:", r2_score(y_test, y_pred))
```

## äº”ã€é«˜çº§åŠŸèƒ½

### 1. **Pipelineï¼ˆç®¡é“ï¼‰**

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

# åˆ›å»ºç®¡é“
pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('svc', SVC())
])

# ä¸€æ­¥å®Œæˆè®­ç»ƒ
pipe.fit(X_train, y_train)
y_pred = pipe.predict(X_test)
```

### 2. **ç½‘æ ¼æœç´¢è°ƒå‚**

```python
from sklearn.model_selection import GridSearchCV

# å®šä¹‰å‚æ•°ç½‘æ ¼
param_grid = {
    'C': [0.1, 1, 10],
    'gamma': [0.001, 0.01, 0.1],
    'kernel': ['rbf', 'linear']
}

# ç½‘æ ¼æœç´¢
grid_search = GridSearchCV(SVC(), param_grid, cv=5)
grid_search.fit(X_train, y_train)

print("æœ€ä½³å‚æ•°:", grid_search.best_params_)
print("æœ€ä½³åˆ†æ•°:", grid_search.best_score_)
```

### 3. **äº¤å‰éªŒè¯**

```python
from sklearn.model_selection import cross_val_score

model = RandomForestClassifier()
scores = cross_val_score(model, X, y, cv=5)

print("äº¤å‰éªŒè¯åˆ†æ•°:", scores)
print("å¹³å‡åˆ†æ•°:", scores.mean())
```

### 4. **ç‰¹å¾å·¥ç¨‹**

```python
from sklearn.feature_selection import SelectKBest, f_classif

# é€‰æ‹©Kä¸ªæœ€ä½³ç‰¹å¾
selector = SelectKBest(f_classif, k=2)
X_new = selector.fit_transform(X, y)

# æŸ¥çœ‹è¢«é€‰æ‹©çš„ç‰¹å¾
selected_features = selector.get_support(indices=True)
print("é€‰æ‹©çš„ç‰¹å¾ç´¢å¼•:", selected_features)
```

## å…­ã€å¸¸ç”¨ç®—æ³•å¯¹æ¯”

| ç®—æ³•ç±»å‹     | é€‚ç”¨åœºæ™¯  | ä¼˜ç‚¹    | ç¼ºç‚¹    |
| -------- | ----- | ----- | ----- |
| **é€»è¾‘å›å½’** | äºŒåˆ†ç±»   | ç®€å•å¿«é€Ÿ  | çº¿æ€§å‡è®¾  |
| **å†³ç­–æ ‘**  | åˆ†ç±»/å›å½’ | å¯è§£é‡Šæ€§å¼º | æ˜“è¿‡æ‹Ÿåˆ  |
| **éšæœºæ£®æ—** | åˆ†ç±»/å›å½’ | å‡†ç¡®ç‡é«˜  | è®­ç»ƒæ…¢   |
| **SVM**  | é«˜ç»´æ•°æ®  | æ•ˆæœå¥½   | å¤§æ•°æ®é›†æ…¢ |
| **KNN**  | å°æ•°æ®é›†  | æ— éœ€è®­ç»ƒ  | é¢„æµ‹æ…¢   |

## ä¸ƒã€å®ç”¨æŠ€å·§

### 1. **ä¿å­˜å’ŒåŠ è½½æ¨¡å‹**

```python
import joblib

# ä¿å­˜
joblib.dump(model, 'model.pkl')

# åŠ è½½
model = joblib.load('model.pkl')
```

### 2. **å¤„ç†ä¸å¹³è¡¡æ•°æ®**

```python
from sklearn.utils import resample

# æˆ–ä½¿ç”¨class_weightå‚æ•°
model = RandomForestClassifier(class_weight='balanced')
```

### 3. **æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§**

```python
# æ ‘æ¨¡å‹
importances = model.feature_importances_
for i, importance in enumerate(importances):
    print(f"ç‰¹å¾ {i}: {importance}")
```

## å…«ã€å­¦ä¹ å»ºè®®

1. **ä»ç®€å•ç®—æ³•å¼€å§‹**ï¼šå…ˆæŒæ¡çº¿æ€§å›å½’ã€é€»è¾‘å›å½’
2. **ç†è§£APIè®¾è®¡**ï¼šfitã€predictã€transformæ¨¡å¼
3. **æ³¨é‡æ•°æ®é¢„å¤„ç†**ï¼šå½’ä¸€åŒ–ã€ç¼ºå¤±å€¼å¤„ç†
4. **äº¤å‰éªŒè¯**ï¼šé¿å…è¿‡æ‹Ÿåˆ
5. **å®è·µé¡¹ç›®**ï¼šKaggleç«èµ›ã€çœŸå®æ•°æ®é›†

éœ€è¦æˆ‘è¯¦ç»†è®²è§£æŸä¸ªç‰¹å®šéƒ¨åˆ†å—ï¼Ÿ
